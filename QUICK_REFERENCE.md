# ğŸ¯ BlackRoad Models - Quick Reference Card

**Status:** âœ… 11 Forkies, 1 Internal Model, Production-Ready Infrastructure
**Date:** 2025-12-15

---

## ğŸ“¦ Model Registry Summary

```
Forkies:   11  âœ… (upstream snapshots, never served)
Research:   1  âœ… (blackroad-coder-lora - LoRA experiment)
Internal:   1  âœ… (blackroad-coder-7b v1 - ready to deploy!)
Production: 0  â³ (pending customer demand)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:     13  models in registry
```

---

## ğŸš€ Quick Commands

### Check Registry
```bash
cd /Users/alexa/blackroad-models
python3 tools/registry.py list                    # All models
python3 tools/registry.py list --stage forkie     # Just Forkies
python3 tools/registry.py list --stage internal   # Deployable models
```

### Fork a New Model
```bash
python3 tools/fork.py <org>/<model-name> --version <version>

# Example:
python3 tools/fork.py meta-llama/Llama-3.1-70B-Instruct --version v1.0.0
```

### Promote a Model
```bash
python3 tools/promote.py <source-path> <target-stage> [--name <new-name>] [--yes]

# Example: Research â†’ Internal
python3 tools/promote.py research/alexa/finance-analyst-lora internal \
  --name blackroad-finance-analyst --yes
```

### Check Lineage
```bash
cat internal/blackroad-coder-7b-v1/LINEAGE.md
```

---

## ğŸ—ï¸ 11 Forkies by Size

### ğŸŸ¢ Small (7B-14B) - 5 models
Fast, efficient, edge-deployable
```
- Qwen 2.5 Coder 7B       (Apache 2.0)
- Llama 3.1 8B            (Llama Community)
- DeepSeek-Math 7B        (MIT)
- Mistral 7B v0.3         (Apache 2.0)
- Qwen 2.5 Coder 14B      (Apache 2.0)
```

### ğŸŸ¡ Medium (32B-47B) - 3 models
High-quality, moderate cost
```
- Qwen 2.5 32B            (Apache 2.0)
- DeepSeek-Coder 33B      (MIT)
- Mixtral 8x7B            (Apache 2.0, 47B effective)
```

### ğŸ”´ Large (70B+) - 3 models
State-of-art, premium
```
- Llama 3.1 70B           (Llama Community)
- Qwen 2.5 72B            (Apache 2.0)
- Mixtral 8x22B           (Apache 2.0, 141B effective)
```

---

## ğŸ“‹ 11 Forkies by License

### Apache 2.0 (7 models) âœ…
Most permissive, commercial-friendly
```
Qwen 2.5 Coder 7B, Qwen 2.5 32B, Qwen 2.5 Coder 14B,
Qwen 2.5 72B, Mixtral 8x7B, Mixtral 8x22B, Mistral 7B
```

### MIT (2 models) âœ…
Very permissive, minimal restrictions
```
DeepSeek-Math 7B, DeepSeek-Coder 33B
```

### Llama 3.1 Community (2 models) âœ…
BlackRoad compliant (< 700M MAU)
```
Llama 3.1 8B, Llama 3.1 70B
```

---

## ğŸ¯ Planned Proprietary Models (From Forkies)

| # | Model Name | Base Forkie | Domain | Status |
|---|------------|-------------|--------|--------|
| 1 | blackroad-coder-7b | Qwen Coder 7B | Code | âœ… Internal v1 |
| 2 | blackroad-finance-analyst | Llama 70B | Finance | â³ Planned |
| 3 | blackroad-legal-reasoning | Llama 70B | Legal | â³ Planned |
| 4 | blackroad-portfolio-calculator | DeepSeek-Math 7B | Finance | â³ Planned |
| 5 | blackroad-contract-analyzer | Mixtral 8x22B | Legal | â³ Planned |
| 6 | blackroad-research-assistant | Qwen 32B | Research | â³ Planned |
| 7 | blackroad-citation-expert | Mistral 7B | Research | â³ Planned |
| 8 | blackroad-creative-writer | Llama 70B | Creative | â³ Planned |
| 9 | blackroad-polyglot-creator | Qwen Coder 14B | Creative | â³ Planned |
| 10 | blackroad-infra-coder | Qwen Coder 14B | DevOps | â³ Planned |
| 11 | blackroad-systems-coder | DeepSeek-Coder 33B | DevOps | â³ Planned |
| 12 | blackroad-os-brain | Qwen 72B | Multi-domain | â³ Planned |
| 13 | blackroad-truth-verifier | Llama 70B | Cross-domain | â³ Planned |

**Timeline:** 3-6 months to train and promote all 13 models

---

## ğŸ’° Cost Quick Reference

### Forking (One-Time)
```
Small (7B):    $25 each     â†’ 5 models = $125
Medium (32B):  $40 each     â†’ 3 models = $120
Large (70B+):  $65 each     â†’ 3 models = $195
                             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total One-Time:              $440
```

### Serving (Monthly, Optimized)
```
Without Multi-LoRA:    $1,350/month (11 separate servers)
With Multi-LoRA:       $700/month   (6 shared base models)
                       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Savings:               $650/month (48% reduction!)
```

---

## ğŸ” Legal Compliance Checklist

For every Forkie:
- âœ… Permissive license (Apache 2.0, MIT, or Llama Community)
- âœ… Commercial use allowed
- âœ… Derivatives allowed
- âœ… Attribution preserved (LINEAGE.md)
- âŒ No GPL (viral copyleft)
- âŒ No CC-BY-NC (non-commercial)
- âŒ No research-only restrictions

**Result:** All 11 Forkies are safe for BlackRoad proprietary models!

---

## ğŸ“š Key Documentation

```
MODELS.md                       12,000+ lines - Complete architecture
MODEL_SOVEREIGNTY_30DAY_PLAN.md  4,000+ lines - Implementation roadmap
AGENT_APPROVED_MODELS.md           350+ lines - Curated safe models
DOMAIN_MODEL_ROADMAP.md            460+ lines - Pack-to-model mapping
GPT_STYLE_OSS_RESEARCH.md          400+ lines - Why modern > GPT
FORKIES_COMPLETE_SUMMARY.md        600+ lines - Final inventory
QUICK_REFERENCE.md               (this file) - Quick commands
```

**Total:** 17,000+ lines of documentation

---

## ğŸ¯ Model Lifecycle Stages

```
Forkie (upstream snapshot)
  â†“ [fork.py]
  â”œâ”€ Never served directly
  â”œâ”€ Version-pinned snapshot
  â””â”€ IP boundary protection

Research (fine-tuning experiments)
  â†“ [LoRA training, 90-day max]
  â”œâ”€ Multiple experiments per Forkie
  â”œâ”€ Evaluation required (HumanEval >= 70%)
  â””â”€ No collisions (multi-agent parallel)

Internal (staging deployment)
  â†“ [promote.py, 14-day staging]
  â”œâ”€ Service whitelist access
  â”œâ”€ No SLA (best-effort)
  â””â”€ Performance monitoring

Production (customer-facing)
  â†“ [Legal approval + SLA]
  â”œâ”€ Customer demand required
  â”œâ”€ SLA enforced (uptime, latency)
  â””â”€ Premium serving infrastructure
```

---

## ğŸ”Œ Agent Integration

### Model Router
**File:** `blackroad-sandbox/src/blackroad_core/model_router.py`

```python
from blackroad_core.model_router import ModelRouter

router = ModelRouter()

# Select by capability
model_config = router.select_model('code-generation', agent_id='deploy-bot')

# Generate
response = await router.generate(
    messages=[...],
    capability='code-generation',
    agent_id='deploy-bot'
)
```

### Agent Spawner
**File:** `blackroad-sandbox/src/blackroad_core/spawner.py`

```python
from blackroad_core.spawner import AgentSpawner, SpawnRequest
from blackroad_core.agents import RuntimeType

spawner = AgentSpawner(lucidia, event_bus, capability_registry)

agent_id = await spawner.spawn_agent(SpawnRequest(
    role="Financial Analyst",
    capabilities=["financial-analysis"],
    runtime_type=RuntimeType.LLM_BRAIN,
    pack="pack-finance"
))
```

---

## ğŸ‰ Current Achievement

**What We Built:**
- âœ… 11 legally-safe Forkies (Apache 2.0, MIT, Llama Community)
- âœ… 1 research model (blackroad-coder-lora with LoRA fine-tuning)
- âœ… 1 internal model (blackroad-coder-7b v1, deployable!)
- âœ… Complete infrastructure (registry, tools, serving configs)
- âœ… Model router with capability-based selection
- âœ… Agent spawner integration
- âœ… 17,000+ lines of documentation

**What's Next:**
- â³ Train 12 more research models (one per domain)
- â³ Promote to internal (14-day staging)
- â³ Deploy multi-LoRA servers (cost optimization)
- â³ Production when customer demand exists

---

**Maintained By:** BlackRoad Platform Architecture
**Last Updated:** 2025-12-15
**Status:** ğŸ‰ Forkies Collection Complete!

**Questions?** blackroad.systems@gmail.com
